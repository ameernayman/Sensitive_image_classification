{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Text_Classification.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ameernayman/Sensitive_image_classification/blob/main/Text_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sM59X-o79RgC"
      },
      "source": [
        "# Sensitive Data classification for text\n",
        "\n",
        "##  This model run in google colab https://colab.research.google.com/"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import json\n",
        "import os\n",
        "import random\n",
        "\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ],
      "metadata": {
        "id": "8KD86wyWoQ0v"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "leaIgZqWI9HX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "371d1df3-0f0b-4f26-dcb0-cf04d000d551"
      },
      "source": [
        "\n",
        "text_folder = \"/content/Sensitive_image_classification\"\n",
        "if os.path.exists(text_folder) == False:\n",
        "  !git clone https://github.com/ameernayman/Sensitive_image_classification.git\n",
        "\n",
        "dataset_text = text_folder + \"/dataset_text/\"\n",
        "sensitive_json = \"data_sensitive.json\"\n",
        "nonsensitive_json = \"data_nonsensitive.json\""
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Sensitive_image_classification'...\n",
            "remote: Enumerating objects: 715, done.\u001b[K\n",
            "remote: Counting objects: 100% (6/6), done.\u001b[K\n",
            "remote: Compressing objects: 100% (6/6), done.\u001b[K\n",
            "remote: Total 715 (delta 0), reused 2 (delta 0), pack-reused 709\u001b[K\n",
            "Receiving objects: 100% (715/715), 93.30 MiB | 34.35 MiB/s, done.\n",
            "Resolving deltas: 100% (1/1), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7i3YvPoe9ZaT"
      },
      "source": [
        "### Text model Preprocessing the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vIUEAZOfJyy-",
        "outputId": "4a2722c3-c5a4-45c8-b3ca-0874e171ac43"
      },
      "source": [
        "textData = []\n",
        "textSentences = []\n",
        "textLabels = []\n",
        "\n",
        "stopwords = [ \"a\", \"about\", \"above\", \"after\", \"again\", \"against\", \"all\", \"am\", \"an\", \"and\", \"any\", \"are\", \"as\", \"at\", \"be\", \"because\", \"been\", \"before\", \"being\", \"below\", \"between\", \"both\", \"but\", \"by\", \"could\", \"did\", \"do\", \"does\", \"doing\", \"down\", \"during\", \"each\", \"few\", \"for\", \"from\", \"further\", \"had\", \"has\", \"have\", \"having\", \"he\", \"he'd\", \"he'll\", \"he's\", \"her\", \"here\", \"here's\", \"hers\", \"herself\", \"him\", \"himself\", \"his\", \"how\", \"how's\", \"i\", \"i'd\", \"i'll\", \"i'm\", \"i've\", \"if\", \"in\", \"into\", \"is\", \"it\", \"it's\", \"its\", \"itself\", \"let's\", \"me\", \"more\", \"most\", \"my\", \"myself\", \"nor\", \"of\", \"on\", \"once\", \"only\", \"or\", \"other\", \"ought\", \"our\", \"ours\", \"ourselves\", \"out\", \"over\", \"own\", \"same\", \"she\", \"she'd\", \"she'll\", \"she's\", \"should\", \"so\", \"some\", \"such\", \"than\", \"that\", \"that's\", \"the\", \"their\", \"theirs\", \"them\", \"themselves\", \"then\", \"there\", \"there's\", \"these\", \"they\", \"they'd\", \"they'll\", \"they're\", \"they've\", \"this\", \"those\", \"through\", \"to\", \"too\", \"under\", \"until\", \"up\", \"very\", \"was\", \"we\", \"we'd\", \"we'll\", \"we're\", \"we've\", \"were\", \"what\", \"what's\", \"when\", \"when's\", \"where\", \"where's\", \"which\", \"while\", \"who\", \"who's\", \"whom\", \"why\", \"why's\", \"with\", \"would\", \"you\", \"you'd\", \"you'll\", \"you're\", \"you've\", \"your\", \"yours\", \"yourself\", \"yourselves\" ]\n",
        "\n",
        "def load_data(filename):\n",
        "  with open(dataset_text + filename, 'r') as f:\n",
        "      data_store = json.load(f)\n",
        "  for value in data_store:\n",
        "    textSentences = value['data']\n",
        "    textLabels = value['is_sensitive']\n",
        "    for wrd in stopwords: \n",
        "      token = \" \" + wrd + \" \"\n",
        "      textSentences = textSentences.replace(token, \" \")\n",
        "    textData.append([textSentences, textLabels])\n",
        "\n",
        "\n",
        "load_data(sensitive_json)\n",
        "load_data(nonsensitive_json)\n",
        "\n",
        "random.shuffle(textData)\n",
        "\n",
        "\n",
        "for item in textData:\n",
        "  textSentences.append(item[0])\n",
        "  textLabels.append(item[1])\n",
        "\n",
        "\n",
        "training_snt_text= textSentences[0:size_training]\n",
        "validation_snt_text = textSentences[size_training:]\n",
        "training_lbls_text = textLabels[0:size_training]\n",
        "validation_lbls_text = textLabels[size_training:]\n",
        "\n",
        "print(\"Size of Training Data set is: \", len(training_snt_text))\n",
        "print(\"Training Data Sample:\", training_snt_text[0])\n",
        "print(\"Size of Validation Data set is: \", len(validation_snt_text))\n",
        "print(\"Validation Sample:\", validation_snt_text[0])"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size of Training Data set is:  25000\n",
            "Training Data Sample: The President United States nominates Robert A. Leffingwell Secretary State. The second-term President, ill, chosen part not believe Vice President Harley Hudson—whom others usually ignore—will successfully continue administration's foreign policy die.\n",
            "Leffingwell's nomination controversial within United States Senate which, using advice consent powers, must either approve reject appointment. Both President's party, majority, minority divided. Majority Leader Bob Munson, senior senator Michigan, loyally supports nominee despite doubts, hard-working Majority Whip Stanley Danta Connecticut womanizer Lafe Smith Rhode Island. Demagogic peace advocate Fred Van Ackerman Wyoming especially supportive, spite Munson repeatedly advising not aggravate situation. Although also majority party, President pro tempore \"curmudgeon\" Seabright \"Seab\" Cooley South Carolina dislikes Leffingwell personal professional reasons, leads opposition.\n",
            "The Senate Foreign Relations Committee appoints subcommittee, chaired majority member Brigham Anderson Utah, evaluate nominee. The young devoted family man undecided Leffingwell. Cooley dramatically introduces surprise witness, Herbert Gelman, subcommittee's hearing. The minor Treasury clerk testifies briefly Communist cell Leffingwell two others University Chicago. Leffingwell denies charge effectively questions Gelman's credibility, later tells President committed perjury Gelman essentially correct. He asks President withdraw nomination, President refuses.\n",
            "Cooley identifies another member cell, senior Treasury official Hardiman Fletcher. He forces Fletcher confess Anderson, tells Munson. Despite personal lobbying President, subcommittee chairman insists White House withdraw nomination due Leffingwell's perjury will subpoena Fletcher testify. The President angrily refuses majority leader admits White House will soon nominate another candidate. Anderson delays committee's report Leffingwell, President sends Fletcher country, angering senator.\n",
            "Anderson wife receive anonymous phone calls Van Ackerman's men warning unless subcommittee reports favorably Leffingwell, information happened \"Ray\" Hawaii will appear. A worried Anderson visits fellow Army veteran, Ray Shaff, New York. Shaff admits sold evidence past homosexual relationship two. Hudson, Anderson's friend Smith, others attempt counsel troubled chairman but, unable reconcile duty secret, Anderson commits suicide.\n",
            "The President denies knowing blackmail Munson Hudson. He tells majority leader dying Leffingwell's confirmation vital. Munson criticizes Cooley opposing nominee not exposing Fletcher, forcing Anderson bear pressure alone. Anderson's death, nonetheless, permits subcommittee Foreign Relations Committee proceed nomination. Both report favorably full Senate.\n",
            "In Senate Chamber Cooley apologizes \"vindictiveness\". While will vote Leffingwell \"alien voice\", senator will not ask others follow. Munson, moved Cooley's action, cites \"tragic circumstances\" surrounding confirmation. Although majority leader will vote Leffingwell, will permit conscience vote others. Hudson's quorum call majority leader's refusal yield floor prevent Van Ackerman speaking Munson asks \"Yeas Nays\", ending debate. The majority leader tells Van Ackerman not Andersons' privacy, Senate censure expel him. Van Ackerman leaves chamber vote.\n",
            "Munson's side slightly ahead Smith unexpectedly votes Leffingwell, majority leader prepares Vice President break tie nominee's favor. Secret Service agents enter chamber Hudson receives message Senate Chaplain. He announces will not break tie, causing nomination fail, President died vote. As leaves Secret Service, Hudson tells Munson wants choose Secretary State. The film ends Munson makes motion adjourn due former president's death.\n",
            "Size of Validation Data set is:  6576\n",
            "Validation Sample: Fashion merchandising student Elle Woods everything: rich, pretty, popular, straight-A student, handsome boyfriend president sorority Delta Nu. Elle taken expensive restaurant boyfriend, governor's son, Warner Huntington III. She expects Warner propose marriage, breaks instead, reasoning not serious enough political aspirations. Her sorority sisters encourage pursue him. After reading magazine article Warner's brother getting engaged socialite, Elle decides enroll law school order win back Warner. After much effort, Elle scores 179 180 Law School Admission Test. Her score, combined 4.0 GPA, admissions essay video, strong extracurricular activities, gains admission Harvard Law School, Warner enrolled.\n",
            "Upon arriving Harvard, Elle's SoCal personality complete contrast East Coast classmates' personalities, refuse take seriously. She soon encounters Warner asks meet later first class. Elle struggles keep reading unprepared lecture, causes strict Professor Stromwell, well another student Vivian Kensington, berate force class. Outside courtyard, Elle meets Emmett, associate Harvard gives advice handling professors. She meets Warner discovers engaged Vivian, girl humiliated Stromwell's class. Leaving huff, Elle finds nearest salon ease anger meets Paulette, beautician befriends recollects times man rejected her. Paulette’s dog Rufus confiscated now hands ex. Elle tearfully tells Paulette situation Paulette encourages \"steal bastard back.\"\n",
            "Elle tries blend others, even making effort join Warner friends study group unsuccessful. She overhears Vivian inviting people party tells Elle \"costume party\" says can come. Elle arrives party Playboy bunny suit sees party not costume party. Elle tells Warner intends apply Professor Callahan's prestigious internship, Warner tells not smart enough wasting time. Elle realizes Warner will never take back finds motivation prove herself. She helping Paulette reclaim dog ex Dewey Newcomb, stating long relationship counts common-law marriage, Paulette allowed keep dog.\n",
            "After several months dramatic improvement, Elle, along Warner, Vivian another student Enid Wexler, given surprise internship Callahan's law office. Callahan defending prominent fitness instructor named Brooke Windham, one Elle's role models former member sorority. Accused murdering wealthy husband, Brooke unwilling produce alibi. She later tells Elle liposuction time husband's murder refused tell Callahan media fearing will destroy career. Discussing trial, defending team tries persuade Elle reveal Brooke's alibi, refuses do. Warner attempts convince her, saying shares alibi Callahan might hire summer associate not worry Brooke think herself. Vivian overhearing disgusted Warner's lack empathy ethical stance means get ahead.\n",
            "Elle Emmett get assigned Callahan meet murder victim's ex-wife spa question Brooke. The ex-wife claims Brooke bad stepmother daughter Chutney Brooke eye family's pool cleaner, Elle doesn't believe her. As Elle returns dorm-room, encounters one kind, awkward, classmates attempting ask girl date. The girl says no humiliates him. Elle interrupts feigns amazing sexual encounter together successful effort make seem desirable. Vivian approaches Elle's dorm compliment integrity trial. Clearly disturbed Warner's behavior earlier, continues bond Elle make fun Warner's privileged upbringing reveals Warner put wait list first applied Harvard father \"had make call,\" much Elle's surprise.\n",
            "Back salon, UPS delivery man catches Paulette’s eye, Paulette speechless, not knowing communicate she’s attracted him. Elle asks Paulette first time actually talking other, Paulette still speechless, Elle decides teach her, along rest salon, technique learned captivate boys, called “Bend Snap”. Soon Elle seen teaching entire salon Bend Snap hilarious montage, Paulette meets eyes UPS guy again, tries new move ends breaking nose process.\n",
            "At trial, Enrique Salvatore, pool cleaner prosecution's main witness, says affair Brooke planning run off husband's money. Elle deduces Enrique gay knew designer brand shoes wearing, points Emmett gay men normally know designers straight men don't. Brooke recalls left 'Cher' tape pool house. Armed knowledge, Emmett, cross examination, redirects tricks Enrique outing admitting boyfriend named Chuck; attempting deny revelation, Chuck stands effeminately shouts \"You Bitch!\" storming courtroom. In uproar, judge calls order dismisses Enrique trial resumes.\n",
            "Apparently impressed, Callahan asks Elle meet office later evening. In office evening, Callahan makes pass Elle offering \"discuss future career.\" Vivian, approaching office, saw Callahan trying seduce Elle, assuming Elle willing relying attractiveness succeed. Vivian storms Callahan's office, telling Elle reason Elle gotten far attractiveness. Despondent, Elle decides quit internship.\n",
            "As preparing move back California, Elle stops salon say goodbye Paulette. She tells that, despite people not taking seriously, internship made feel confident Callahan gave wanted sex her. As drop law school leave, Professor Stromwell, happened salon, reassures motivates want stay. Later on, Emmett explains Brooke Callahan's behavior caused Elle quit internship, Vivian now regrets judgment Elle. Brooke happily fires Callahan enters courtroom reveals Elle replacement defense. Despite law student status, Massachusetts' Supreme Judicial Court ruling 3.03 allows Elle legally appear defendant's behalf supervision licensed attorney. Callahan refuses sponsor her, Emmett immediately accepts supervise instead. Nervous first, Elle cross-examines Brooke's step-daughter Chutney. Chutney claims not hear gun shot upstairs taking shower time apparent murder. Elle catches Chutney lie says gotten perm done less 24 hours prior incident. Elle confidently lures Chutney expose faulty alibi correctly points applying water shampoo hair within 24 hour period deactivates ammonium thioglycolate used perming hair. She continues cross-examine Chutney anyone sustained many 30+ perm treatments life \"well aware rule\". Now panic, Chutney tears unwittingly reveals intended shoot Brooke accidentally shot killed father mistake, thinking Brooke entered house.\n",
            "Elle won first case charges Brooke dismissed. Chutney taken custody. Warner approaches Elle tells loves tries convince take back. She rejects advances mocks repeating earlier line wasn't serious enough him, cuts ties him. Two years later, Elle graduates Harvard gives graduation speech. Vivian broke off engagement Warner now Elle's best friend. Warner graduated no honors, no girlfriend, no job offers. Paulette ended marrying UPS guy, expecting first child together, girl plan name Elle. Emmett started firm Elle dating since trial, plans propose later night.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kt01OaiEMbQ9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f34687e-f1e8-4dab-f615-a2e19d5d23fd"
      },
      "source": [
        "\n",
        "type_trunc='post'\n",
        "padding='post'\n",
        "out_of_vocb = \"<OOV>\"\n",
        "size_training = 25000\n",
        "length_text = 60\n",
        "size_vocab = 3000\n",
        "tknizer = Tokenizer(num_words=size_vocab, oov_token=out_of_vocb)\n",
        "\n",
        "tknizer.fit_on_texts(training_snt_text)\n",
        "\n",
        "index_words = tknizer.word_index\n",
        "print(\"Size of word index:\", len(index_words))\n",
        "\n",
        "with open(\"word_index.json\", \"w\") as outfile:  \n",
        "    json.dump(index_words, outfile)\n",
        "    print(\"Saving the word index as JSON\")\n",
        "\n",
        "\n",
        "training_squnce = tknizer.texts_to_sequences(training_snt_text)\n",
        "padding_Tdataset = pad_sequences(training_squnce, maxlen=length_text, padding=padding, truncating=type_trunc)\n",
        "\n",
        "# Apply the same for validation data\n",
        "validation_squnce = tknizer.texts_to_sequences(validation_snt_text)\n",
        "padding_Vdataset = pad_sequences(validation_squnce, maxlen=length_text, padding=padding, truncating=type_trunc)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size of word index: 116618\n",
            "Saving the word index as JSON\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SSHwIoCLPKPq"
      },
      "source": [
        "\n",
        "import numpy\n",
        "padding_Tdataset = numpy.array(padding_Tdataset)\n",
        "training_lbls_text = numpy.array(training_lbls_text)\n",
        "padding_Vdataset = numpy.array(padding_Vdataset)\n",
        "validation_lbls_text = numpy.array(validation_lbls_text)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9OLtjmJw9ehH"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p5ADD9CuNFWB",
        "outputId": "578f6885-ee3c-4388-ae5f-be79be8c84d0"
      },
      "source": [
        "dimensions = 32\n",
        "ACCURACY = 0.99\n",
        "class myEpoch(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "    if logs.get('accuracy') > ACCURACY:\n",
        "      print(\"Reached 99.9% accuracy so cancelling training!\")\n",
        "      self.model.stop_training = True\n",
        "\n",
        "epoch_callbacks = myEpoch()\n",
        "\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(size_vocab, dimensions, input_length=length_text),\n",
        "    tf.keras.layers.Conv1D(64, 5, activation='relu'),\n",
        "    tf.keras.layers.GlobalAveragePooling1D(),\n",
        "    tf.keras.layers.Dense(24, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "\n",
        "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 60, 32)            96000     \n",
            "                                                                 \n",
            " conv1d (Conv1D)             (None, 56, 64)            10304     \n",
            "                                                                 \n",
            " global_average_pooling1d (G  (None, 64)               0         \n",
            " lobalAveragePooling1D)                                          \n",
            "                                                                 \n",
            " dense (Dense)               (None, 24)                1560      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 25        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 107,889\n",
            "Trainable params: 107,889\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mb2NlD159g8k"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7TP5ThxvNPK8",
        "outputId": "a8a0ce93-c24f-4067-d296-242224b07fff"
      },
      "source": [
        "num_epochs = 15\n",
        "\n",
        "# model.fit - Train the model for a fixed number of epochs\n",
        "history = model.fit(training_padded, \n",
        "                    training_labels, \n",
        "                    epochs=num_epochs, \n",
        "                    validation_data=(\n",
        "                        validation_padded, \n",
        "                        validation_labels), \n",
        "                    verbose=1)\n",
        "                    #callbacks=[callbacks])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "782/782 [==============================] - 6s 6ms/step - loss: 0.0490 - accuracy: 0.9928 - val_loss: 0.0040 - val_accuracy: 0.9991\n",
            "Epoch 2/15\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 0.0014 - accuracy: 0.9997 - val_loss: 0.0031 - val_accuracy: 0.9991\n",
            "Epoch 3/15\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 6.8782e-04 - accuracy: 0.9998 - val_loss: 0.0015 - val_accuracy: 0.9995\n",
            "Epoch 4/15\n",
            "782/782 [==============================] - 4s 6ms/step - loss: 3.7045e-04 - accuracy: 0.9999 - val_loss: 0.0017 - val_accuracy: 0.9995\n",
            "Epoch 5/15\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 2.6924e-04 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 0.9995\n",
            "Epoch 6/15\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 2.4431e-04 - accuracy: 1.0000 - val_loss: 4.5207e-04 - val_accuracy: 0.9998\n",
            "Epoch 7/15\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 2.0030e-04 - accuracy: 1.0000 - val_loss: 5.9146e-04 - val_accuracy: 0.9998\n",
            "Epoch 8/15\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 1.4301e-04 - accuracy: 1.0000 - val_loss: 4.5290e-04 - val_accuracy: 0.9998\n",
            "Epoch 9/15\n",
            "782/782 [==============================] - 4s 6ms/step - loss: 1.0017e-04 - accuracy: 1.0000 - val_loss: 1.6199e-04 - val_accuracy: 0.9998\n",
            "Epoch 10/15\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 4.4268e-05 - accuracy: 1.0000 - val_loss: 5.6570e-05 - val_accuracy: 1.0000\n",
            "Epoch 11/15\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 4.8008e-06 - accuracy: 1.0000 - val_loss: 6.4852e-05 - val_accuracy: 1.0000\n",
            "Epoch 12/15\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 2.9102e-06 - accuracy: 1.0000 - val_loss: 5.8143e-05 - val_accuracy: 1.0000\n",
            "Epoch 13/15\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 1.9035e-06 - accuracy: 1.0000 - val_loss: 5.5504e-05 - val_accuracy: 1.0000\n",
            "Epoch 14/15\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 1.5203e-06 - accuracy: 1.0000 - val_loss: 3.3928e-05 - val_accuracy: 1.0000\n",
            "Epoch 15/15\n",
            "782/782 [==============================] - 5s 6ms/step - loss: 9.2568e-07 - accuracy: 1.0000 - val_loss: 2.0561e-05 - val_accuracy: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "poN5h1SD9tiE"
      },
      "source": [
        "## Plotting Accuracy and Loss Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WCDbITWsNWlI"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plot the accuracy and loss functions\n",
        "def plot_graphs(history, string):\n",
        "  plt.plot(history.history[string])\n",
        "  plt.plot(history.history['val_'+string])\n",
        "  plt.xlabel(\"Epochs\")\n",
        "  plt.ylabel(string)\n",
        "  plt.legend([string, 'val_'+string])\n",
        "  plt.show()\n",
        "  \n",
        "plot_graphs(history, \"accuracy\")\n",
        "plot_graphs(history, \"loss\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z9ymTQswYUQz"
      },
      "source": [
        "## Confusion Matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tVdCGN-tYXqX"
      },
      "source": [
        "import seaborn\n",
        "print('Confusion Matrix')\n",
        "y_predicted = model.predict(validation_padded)\n",
        "y_predicted_labels = y_predicted > 0.5\n",
        "\n",
        "size = np.size(y_predicted_labels)\n",
        "y_predicted_labels = y_predicted_labels.reshape(size, )\n",
        "\n",
        "for i in range (1, 5):\n",
        "  total = i * size // 4\n",
        "  cm = tf.math.confusion_matrix(labels=validation_labels[0:total],predictions=y_predicted_labels[0:total])\n",
        "\n",
        "  # Calculate accuracy\n",
        "  cm_np = cm.numpy()\n",
        "  conf_acc = (cm_np[0, 0] + cm_np[1, 1])/ np.sum(cm_np) * 100\n",
        "  print(\"Accuracy for\", str(total), \"Test Data = \", conf_acc)\n",
        "\n",
        "  # Plot the confusion matrix\n",
        "  plt.figure(figsize = (10,7))\n",
        "  seaborn.heatmap(cm, annot=True, fmt='d')\n",
        "  plt.title(\"Confusion Matrix for \" + str(total) + \" Test Data\")\n",
        "  plt.xlabel('Predicted')\n",
        "  plt.ylabel('Expected')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f94fRNNo-386"
      },
      "source": [
        "## Saving the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F_rBTIVTQHow"
      },
      "source": [
        "# Save and convert the model (Used for deploying in web application)\n",
        "model.save('model/text_model.h5')\n",
        "print(\"Saved the model successfully\")\n",
        "\n",
        "!apt-get -qq install virtualenv\n",
        "!virtualenv -p python3 venv\n",
        "!source venv/bin/activate\n",
        "!pip install -q tensorflowjs\n",
        "!tensorflowjs_converter --input_format=keras /content/model/text_model.h5 /content/text_model\n",
        "print(\"Model converted to JSON successfully\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "plgECuQc9wdt"
      },
      "source": [
        "## Sample Example"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kyfb-NtpNV7h"
      },
      "source": [
        "# Sample examples\n",
        "sentence = [\"My credit card no is 124345346\", \"game of thrones season finale showing this sunday night\"]\n",
        "sequences = tokenizer.texts_to_sequences(sentence)\n",
        "padded = pad_sequences(sequences, maxlen=length_text, padding=padding_type, truncating=type_trunc)\n",
        "predictions = model.predict(padded)\n",
        "print(\"OUPUT for text model\")\n",
        "for i in range(len(predictions)):\n",
        "  print(predictions[i][0])\n",
        "  if predictions[i][0]>0.5:\n",
        "    print(\"Sensitive - \"+ sentence[i])\n",
        "  else:\n",
        "    print(\"Non-Sensitive - \" + sentence[i] )"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}